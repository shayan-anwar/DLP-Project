{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting seaborn\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.2 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (2.2.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (3.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Installing collected packages: seaborn\n",
            "Successfully installed seaborn-0.13.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.7.0-cp310-cp310-win_amd64.whl.metadata (29 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.2)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.5)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torch-2.7.0-cp310-cp310-win_amd64.whl (212.5 MB)\n",
            "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
            "   - -------------------------------------- 9.4/212.5 MB 49.1 MB/s eta 0:00:05\n",
            "   ---- ----------------------------------- 26.0/212.5 MB 65.9 MB/s eta 0:00:03\n",
            "   ------- -------------------------------- 40.1/212.5 MB 67.2 MB/s eta 0:00:03\n",
            "   -------- ------------------------------- 44.3/212.5 MB 54.2 MB/s eta 0:00:04\n",
            "   --------- ------------------------------ 52.4/212.5 MB 52.2 MB/s eta 0:00:04\n",
            "   ----------- ---------------------------- 58.7/212.5 MB 48.0 MB/s eta 0:00:04\n",
            "   ------------ --------------------------- 68.2/212.5 MB 47.8 MB/s eta 0:00:04\n",
            "   -------------- ------------------------- 76.8/212.5 MB 47.1 MB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 85.2/212.5 MB 46.5 MB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 90.2/212.5 MB 44.3 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 94.9/212.5 MB 42.4 MB/s eta 0:00:03\n",
            "   ------------------ -------------------- 100.1/212.5 MB 40.7 MB/s eta 0:00:03\n",
            "   ------------------- ------------------- 105.1/212.5 MB 39.5 MB/s eta 0:00:03\n",
            "   -------------------- ------------------ 110.4/212.5 MB 38.5 MB/s eta 0:00:03\n",
            "   --------------------- ----------------- 115.6/212.5 MB 37.7 MB/s eta 0:00:03\n",
            "   ---------------------- ---------------- 121.1/212.5 MB 36.8 MB/s eta 0:00:03\n",
            "   ----------------------- --------------- 126.9/212.5 MB 36.3 MB/s eta 0:00:03\n",
            "   ------------------------ -------------- 132.6/212.5 MB 35.9 MB/s eta 0:00:03\n",
            "   ------------------------- ------------- 138.4/212.5 MB 35.5 MB/s eta 0:00:03\n",
            "   -------------------------- ------------ 144.7/212.5 MB 35.2 MB/s eta 0:00:02\n",
            "   --------------------------- ----------- 151.0/212.5 MB 34.8 MB/s eta 0:00:02\n",
            "   ---------------------------- ---------- 157.3/212.5 MB 34.8 MB/s eta 0:00:02\n",
            "   ----------------------------- --------- 162.3/212.5 MB 34.3 MB/s eta 0:00:02\n",
            "   ------------------------------ -------- 165.4/212.5 MB 33.5 MB/s eta 0:00:02\n",
            "   ------------------------------ -------- 167.5/212.5 MB 32.6 MB/s eta 0:00:02\n",
            "   ------------------------------- ------- 169.1/212.5 MB 32.1 MB/s eta 0:00:02\n",
            "   ------------------------------- ------- 170.9/212.5 MB 30.6 MB/s eta 0:00:02\n",
            "   ------------------------------- ------- 172.8/212.5 MB 29.9 MB/s eta 0:00:02\n",
            "   -------------------------------- ------ 174.9/212.5 MB 29.2 MB/s eta 0:00:02\n",
            "   -------------------------------- ------ 176.9/212.5 MB 28.5 MB/s eta 0:00:02\n",
            "   -------------------------------- ------ 178.8/212.5 MB 27.8 MB/s eta 0:00:02\n",
            "   --------------------------------- ----- 180.6/212.5 MB 27.2 MB/s eta 0:00:02\n",
            "   --------------------------------- ----- 182.5/212.5 MB 26.6 MB/s eta 0:00:02\n",
            "   --------------------------------- ----- 184.5/212.5 MB 26.2 MB/s eta 0:00:02\n",
            "   ---------------------------------- ---- 186.1/212.5 MB 25.7 MB/s eta 0:00:02\n",
            "   ---------------------------------- ---- 188.0/212.5 MB 25.1 MB/s eta 0:00:01\n",
            "   ---------------------------------- ---- 189.8/212.5 MB 24.7 MB/s eta 0:00:01\n",
            "   ----------------------------------- --- 191.9/212.5 MB 24.3 MB/s eta 0:00:01\n",
            "   ----------------------------------- --- 194.2/212.5 MB 23.9 MB/s eta 0:00:01\n",
            "   ------------------------------------ -- 196.3/212.5 MB 23.6 MB/s eta 0:00:01\n",
            "   ------------------------------------ -- 198.7/212.5 MB 23.3 MB/s eta 0:00:01\n",
            "   ------------------------------------ -- 201.3/212.5 MB 23.1 MB/s eta 0:00:01\n",
            "   ------------------------------------- - 204.2/212.5 MB 22.8 MB/s eta 0:00:01\n",
            "   ------------------------------------- - 206.8/212.5 MB 22.6 MB/s eta 0:00:01\n",
            "   --------------------------------------  209.5/212.5 MB 22.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  211.8/212.5 MB 22.1 MB/s eta 0:00:01\n",
            "   --------------------------------------  212.3/212.5 MB 22.0 MB/s eta 0:00:01\n",
            "   --------------------------------------  212.3/212.5 MB 22.0 MB/s eta 0:00:01\n",
            "   --------------------------------------  212.3/212.5 MB 22.0 MB/s eta 0:00:01\n",
            "   --------------------------------------  212.3/212.5 MB 22.0 MB/s eta 0:00:01\n",
            "   --------------------------------------  212.3/212.5 MB 22.0 MB/s eta 0:00:01\n",
            "   --------------------------------------  212.3/212.5 MB 22.0 MB/s eta 0:00:01\n",
            "   --------------------------------------  212.3/212.5 MB 22.0 MB/s eta 0:00:01\n",
            "   --------------------------------------  212.3/212.5 MB 22.0 MB/s eta 0:00:01\n",
            "   --------------------------------------- 212.5/212.5 MB 18.5 MB/s eta 0:00:00\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
            "   -------------- ------------------------- 2.4/6.3 MB 12.2 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 5.2/6.3 MB 12.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 6.3/6.3 MB 9.7 MB/s eta 0:00:00\n",
            "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
            "   ------------------------------------ --- 1.6/1.7 MB 11.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.7/1.7 MB 6.7 MB/s eta 0:00:00\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
            "   ---------------------------------------- 536.2/536.2 kB 3.5 MB/s eta 0:00:00\n",
            "Installing collected packages: mpmath, sympy, networkx, fsspec, torch\n",
            "Successfully installed fsspec-2025.3.2 mpmath-1.3.0 networkx-3.4.2 sympy-1.14.0 torch-2.7.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install seaborn\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.7.0)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.22.0-cp310-cp310-win_amd64.whl.metadata (6.3 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.7.0-cp310-cp310-win_amd64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torchvision-0.22.0-cp310-cp310-win_amd64.whl (1.7 MB)\n",
            "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.7/1.7 MB 10.3 MB/s eta 0:00:00\n",
            "Downloading torchaudio-2.7.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
            "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
            "   ------------------------------------- -- 2.4/2.5 MB 44.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.5/2.5 MB 5.5 MB/s eta 0:00:00\n",
            "Installing collected packages: torchvision, torchaudio\n",
            "Successfully installed torchaudio-2.7.0 torchvision-0.22.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.17.0)\n",
            "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.31.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (24.2)\n",
            "Collecting pyyaml>=5.1 (from transformers)\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
            "Requirement already satisfied: requests in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "   ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
            "   ----------------------------------- ---- 9.2/10.4 MB 51.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 10.4/10.4 MB 32.3 MB/s eta 0:00:00\n",
            "Downloading huggingface_hub-0.31.1-py3-none-any.whl (484 kB)\n",
            "Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
            "Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
            "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
            "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
            "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.4/2.4 MB 13.9 MB/s eta 0:00:00\n",
            "Installing collected packages: safetensors, regex, pyyaml, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.31.1 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.51.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.0.2)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-20.0.0-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.31.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (6.0.2)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading aiohttp-3.11.18-cp310-cp310-win_amd64.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: colorama in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading frozenlist-1.6.0-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading multidict-6.4.3-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading propcache-0.3.1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading yarl-1.20.0-cp310-cp310-win_amd64.whl.metadata (74 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "Downloading pyarrow-20.0.0-cp310-cp310-win_amd64.whl (25.8 MB)\n",
            "   ---------------------------------------- 0.0/25.8 MB ? eta -:--:--\n",
            "   ----------- ---------------------------- 7.3/25.8 MB 41.2 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 9.4/25.8 MB 22.5 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 20.4/25.8 MB 33.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  25.4/25.8 MB 30.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  25.7/25.8 MB 30.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 25.8/25.8 MB 21.5 MB/s eta 0:00:00\n",
            "Downloading xxhash-3.5.0-cp310-cp310-win_amd64.whl (30 kB)\n",
            "Downloading aiohttp-3.11.18-cp310-cp310-win_amd64.whl (442 kB)\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading frozenlist-1.6.0-cp310-cp310-win_amd64.whl (120 kB)\n",
            "Downloading multidict-6.4.3-cp310-cp310-win_amd64.whl (38 kB)\n",
            "Downloading propcache-0.3.1-cp310-cp310-win_amd64.whl (45 kB)\n",
            "Downloading yarl-1.20.0-cp310-cp310-win_amd64.whl (92 kB)\n",
            "Installing collected packages: xxhash, pyarrow, propcache, multidict, fsspec, frozenlist, dill, attrs, async-timeout, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 async-timeout-5.0.1 attrs-25.3.0 datasets-3.6.0 dill-0.3.8 frozenlist-1.6.0 fsspec-2025.3.0 multidict-6.4.3 multiprocess-0.70.16 propcache-0.3.1 pyarrow-20.0.0 xxhash-3.5.0 yarl-1.20.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install pandas\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
            "Collecting scipy>=1.6.0 (from scikit-learn)\n",
            "  Downloading scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
            "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.3/11.1 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 1.8/11.1 MB 5.9 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 5.2/11.1 MB 10.3 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 9.2/11.1 MB 13.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.0/11.1 MB 13.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.0/11.1 MB 13.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 11.1/11.1 MB 9.4 MB/s eta 0:00:00\n",
            "Downloading scipy-1.15.2-cp310-cp310-win_amd64.whl (41.2 MB)\n",
            "   ---------------------------------------- 0.0/41.2 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.5/41.2 MB 16.4 MB/s eta 0:00:03\n",
            "   ------------ --------------------------- 12.8/41.2 MB 29.8 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 21.0/41.2 MB 33.1 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 29.1/41.2 MB 34.8 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 37.2/41.2 MB 35.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  41.2/41.2 MB 34.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  41.2/41.2 MB 34.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 41.2/41.2 MB 27.3 MB/s eta 0:00:00\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
            "Successfully installed scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ipywidgets\n",
            "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: comm>=0.1.3 in c:\\users\\fyp-1\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\fyp-1\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets) (8.36.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\fyp-1\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets) (5.14.3)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
            "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
            "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
            "Requirement already satisfied: decorator in c:\\users\\fyp-1\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
            "Requirement already satisfied: exceptiongroup in c:\\users\\fyp-1\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\fyp-1\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\fyp-1\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\fyp-1\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: stack_data in c:\\users\\fyp-1\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
            "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\fyp-1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\fyp-1\\appdata\\roaming\\python\\python310\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\fyp-1\\appdata\\roaming\\python\\python310\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\fyp-1\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\fyp-1\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\fyp-1\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
            "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
            "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
            "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.2/2.2 MB 11.2 MB/s eta 0:00:00\n",
            "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
            "Successfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install ipywidgets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "r-ljNZ2a0_Jj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import zipfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from PIL import Image\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if CUDA is available, otherwise fallback to CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "eVkqys1Z1ErA"
      },
      "outputs": [],
      "source": [
        "# Set random seeds for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MmTYdwd1J41",
        "outputId": "d9a385e0-c4bf-400a-cffd-611707de26d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found archive.zip. Extracting...\n",
            "Extraction complete!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if os.path.exists(r\"C:\\Users\\FYP-1\\Desktop\\LFW dataset\\archive.zip\"):\n",
        "    print(\"Found archive.zip. Extracting...\")\n",
        "    with zipfile.ZipFile(\"archive.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(\".\")\n",
        "    print(\"Extraction complete!\")\n",
        "else:\n",
        "    print(\"archive.zip not found. Please upload the dataset as 'archive.zip'\")\n",
        "    print(\"To upload, click on the files icon in the left sidebar, then click on the upload button.\")\n",
        "    print(\"After uploading, re-run this cell.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuqSouF68egi",
        "outputId": "03684ead-2cd2-4ae9-f6f2-afc0f23bed0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found lfw-funneled.tgz. Extracting...\n",
            "Extraction complete!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tarfile\n",
        "\n",
        "if os.path.exists(\"lfw-funneled.tgz\"):\n",
        "    print(\"Found lfw-funneled.tgz. Extracting...\")\n",
        "    with tarfile.open(\"lfw-funneled.tgz\", 'r:gz') as tar_ref:\n",
        "        tar_ref.extractall(\".\")\n",
        "    print(\"Extraction complete!\")\n",
        "else:\n",
        "    print(\"lfw-funneled.tgz not found. Please upload the dataset as 'lfw-funneled.tgz'\")\n",
        "    print(\"To upload, click on the files icon in the left sidebar, then click on the upload button.\")\n",
        "    print(\"After uploading, re-run this cell.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC1s9SH51QPz",
        "outputId": "20dc040a-19ee-41c2-8b2f-0a0a73713ff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking dataset structure in: lfw_funneled\n",
            "Found 5760 items\n",
            "Sample items: ['Aaron_Eckhart', 'Aaron_Guiel', 'Aaron_Patterson', 'Aaron_Peirsol', 'Aaron_Pena']\n",
            "First item is a directory containing: ['Aaron_Eckhart_0001.jpg']\n",
            "Dataset size: 13233\n",
            "Number of unique people: 5749\n",
            "\n",
            "Sample data:\n",
            "                                          image_path           person\n",
            "0  lfw_funneled\\Aaron_Eckhart\\Aaron_Eckhart_0001.jpg    Aaron_Eckhart\n",
            "1      lfw_funneled\\Aaron_Guiel\\Aaron_Guiel_0001.jpg      Aaron_Guiel\n",
            "2  lfw_funneled\\Aaron_Patterson\\Aaron_Patterson_0...  Aaron_Patterson\n",
            "3  lfw_funneled\\Aaron_Peirsol\\Aaron_Peirsol_0001.jpg    Aaron_Peirsol\n",
            "4  lfw_funneled\\Aaron_Peirsol\\Aaron_Peirsol_0002.jpg    Aaron_Peirsol\n"
          ]
        }
      ],
      "source": [
        "def create_dataframe(data_dir):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    # Print first few directories to understand the structure\n",
        "    print(f\"Checking dataset structure in: {data_dir}\")\n",
        "    all_items = os.listdir(data_dir)\n",
        "    print(f\"Found {len(all_items)} items\")\n",
        "    if len(all_items) > 0:\n",
        "        sample_items = all_items[:5]\n",
        "        print(f\"Sample items: {sample_items}\")\n",
        "\n",
        "        # Check if the first item is a directory\n",
        "        first_item_path = os.path.join(data_dir, all_items[0])\n",
        "        if os.path.isdir(first_item_path):\n",
        "            print(f\"First item is a directory containing: {os.listdir(first_item_path)[:5]}\")\n",
        "\n",
        "    # Process the directory structure\n",
        "    for person_name in os.listdir(data_dir):\n",
        "        person_dir = os.path.join(data_dir, person_name)\n",
        "        if os.path.isdir(person_dir):\n",
        "            for image_name in os.listdir(person_dir):\n",
        "                if image_name.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    image_path = os.path.join(person_dir, image_name)\n",
        "                    image_paths.append(image_path)\n",
        "                    labels.append(person_name)\n",
        "\n",
        "    df = pd.DataFrame({'image_path': image_paths, 'person': labels})\n",
        "    return df\n",
        "\n",
        "# Assuming your dataset is extracted to a folder named 'lfw-deepfunneled'\n",
        "data_dir = 'lfw_funneled'\n",
        "df = create_dataframe(data_dir)\n",
        "print(f\"Dataset size: {len(df)}\")\n",
        "print(f\"Number of unique people: {df['person'].nunique()}\")\n",
        "\n",
        "# Display a sample of the dataframe\n",
        "print(\"\\nSample data:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw563BnN1T3N",
        "outputId": "b178b510-beac-4f87-a731-a09c301717d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Filtered dataset size: 4324\n",
            "Number of people after filtering: 158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\FYP-1\\AppData\\Local\\Temp\\ipykernel_15092\\3710122100.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_filtered['label'] = df_filtered['person'].map(person_to_label)\n"
          ]
        }
      ],
      "source": [
        "# Keep only people with at least 10 images (for better training)\n",
        "counts = df['person'].value_counts()\n",
        "people_to_keep = counts[counts >= 10].index\n",
        "df_filtered = df[df['person'].isin(people_to_keep)]\n",
        "print(f\"\\nFiltered dataset size: {len(df_filtered)}\")\n",
        "print(f\"Number of people after filtering: {df_filtered['person'].nunique()}\")\n",
        "\n",
        "# Create numerical labels\n",
        "person_to_label = {person: idx for idx, person in enumerate(df_filtered['person'].unique())}\n",
        "df_filtered['label'] = df_filtered['person'].map(person_to_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8lPRGdO1X4t",
        "outputId": "7a331a06-e6a4-4f7b-92ce-204cba9888c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 3459\n",
            "Test set size: 865\n"
          ]
        }
      ],
      "source": [
        "# Split into train and test sets\n",
        "train_df, test_df = train_test_split(\n",
        "    df_filtered,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df_filtered['label']\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {len(train_df)}\")\n",
        "print(f\"Test set size: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OAiAgHZG1Zyk"
      },
      "outputs": [],
      "source": [
        "# Create a custom dataset class\n",
        "class LFWDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.dataframe.iloc[idx]['image_path']\n",
        "        label = self.dataframe.iloc[idx]['label']\n",
        "\n",
        "        # Load image\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wl9_QzSc1b89"
      },
      "outputs": [],
      "source": [
        "# Define transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = LFWDataset(train_df, transform=train_transform)\n",
        "test_dataset = LFWDataset(test_df, transform=test_transform)\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "FnKUZ-BJ1e6j"
      },
      "outputs": [],
      "source": [
        "# Visualize some training images\n",
        "def show_batch(dataloader, n=8):\n",
        "    # Get a batch of training data\n",
        "    images, labels = next(iter(dataloader))\n",
        "\n",
        "    # Convert labels to people names\n",
        "    label_to_person = {v: k for k, v in person_to_label.items()}\n",
        "    people = [label_to_person[label.item()] for label in labels]\n",
        "\n",
        "    # Create a grid of images\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i in range(min(n, len(images))):\n",
        "        img = images[i].permute(1, 2, 0).numpy()\n",
        "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "        img = np.clip(img, 0, 1)\n",
        "\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(people[i])\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Uncomment to visualize a batch\n",
        "# show_batch(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmTGa6Gl1i6x",
        "outputId": "086995ed-fe1d-44c9-be4d-b3eb0c6c158c"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained ViT model\n",
        "class FaceRecognitionViT(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(FaceRecognitionViT, self).__init__()\n",
        "        # Load pre-trained ViT model\n",
        "        self.vit = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        # Replace the classifier head\n",
        "        in_features = self.vit.heads.head.in_features\n",
        "        self.vit.heads.head = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vit(x)\n",
        "\n",
        "# Create the model\n",
        "num_classes = df_filtered['label'].nunique()\n",
        "model = FaceRecognitionViT(num_classes)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
        "        images, labels = images.to(device), labels.to(device)  # Move to GPU\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_acc = correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            images, labels = images.to(device), labels.to(device)  # Move to GPU\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    epoch_loss = running_loss / len(test_loader.dataset)\n",
        "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "    return epoch_loss, epoch_acc, all_preds, all_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235,
          "referenced_widgets": [
            "703a241f542b430e949b3262f4b347dc",
            "9e079f6d7f4949c8bd108ca7aba5c2b9",
            "6cd09a1b31c5453a89b24e243e439805",
            "6facbbd81e3c4a61826f50d6542ef41c",
            "cbcafc897ffc4fa49e58ab7b61bcd99b",
            "a8df3b6483ff48a8960e96dfa05a361c",
            "a99dde71ee344f15bdef9470826a2342",
            "49bdd5d56c044345a9edbb4dc03fd083",
            "a40c92eec50c4842a142234253e6d8d7",
            "98c1a6aa84114cbdba324924121dff27",
            "b52630bbce9b4a92901b031b677ea291",
            "460e69820bcf48dda831030fec5044a3",
            "2906f89673614277a53a2fef61aa0beb",
            "56567c26986b4bfa819d145770dab87c",
            "fc1e32eb99174a20b185be1ceb081f31",
            "7d14230e44b24a1b8a0297a5d2025ef1",
            "d1eca1d783ad467997a267a6b61dfec5",
            "8e760bc0d1a449fb934b99fce9116f23",
            "69027df48998421aafe79553abfadbaf",
            "227173aa7e5d4142aac9d8e2c17b130a",
            "ccdbee6153434750b4df465b9d05570f",
            "df332bf7296f4f16aa8933c4b146af9c",
            "7ca15af65f6b4a3983644c4b416c105f",
            "4f87675c770d420781503b68fe783361",
            "6aa7da076b874e55b274814cb086bc58",
            "33f2e68bfe2f4568b32a9f4d70d5e87c",
            "97de03731d934faaa3f4b781983792eb",
            "18b84fd5836244dc99b945b4284e5f08",
            "b615e869ed104fc99c61f77e6b7a8784",
            "b806e317922f4badbd806edca1980233",
            "41e35a849538485bb16b414c86d15634",
            "6c912e3ba4e54cd59cb56d88144d31f8",
            "516fdaaeefff44cc811c2a2b099b4455"
          ]
        },
        "id": "Z9oXqsJK1mYu",
        "outputId": "766e4d83-e5a7-4ded-9339-a362443d3199"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "from tqdm import tqdm  # This is for standard Python scripts\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 3\n",
        "best_val_acc = 0.0\n",
        "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    # Train\n",
        "    train_loss, train_acc = train_model(model, train_loader, criterion, optimizer)\n",
        "\n",
        "    # Evaluate\n",
        "    val_loss, val_acc, preds, true_labels = evaluate_model(model, test_loader, criterion)\n",
        "\n",
        "    # Update learning rate\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Save history\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), 'best_vit_lfw_model.pth')\n",
        "        print(\"Saved best model!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yTmKH-J1oSS"
      },
      "outputs": [],
      "source": [
        "# Visualization of training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['train_loss'], label='Train Loss')\n",
        "plt.plot(history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss Curves')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['train_acc'], label='Train Accuracy')\n",
        "plt.plot(history['val_acc'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy Curves')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFKNDKRg1rfa"
      },
      "outputs": [],
      "source": [
        "# Final evaluation\n",
        "model.load_state_dict(torch.load('best_vit_lfw_model.pth'))\n",
        "val_loss, val_acc, preds, true_labels = evaluate_model(model, test_loader, criterion, device)\n",
        "print(f\"\\nFinal Test Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "label_to_person = {v: k for k, v in person_to_label.items()}\n",
        "target_names = [label_to_person[i] for i in range(num_classes)]\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_labels, preds, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlra2jVl1tCv"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix (for top classes)\n",
        "def plot_confusion_matrix(y_true, y_pred, top_n=20):\n",
        "    # Count occurrences of each class\n",
        "    unique, counts = np.unique(y_true, return_counts=True)\n",
        "\n",
        "    # Get the top N most frequent classes\n",
        "    top_indices = np.argsort(-counts)[:top_n]\n",
        "\n",
        "    # Filter data to include only top classes\n",
        "    mask = np.isin(y_true, top_indices)\n",
        "    y_true_filtered = np.array(y_true)[mask]\n",
        "    y_pred_filtered = np.array(y_pred)[mask]\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(y_true_filtered, y_pred_filtered, labels=top_indices)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=[label_to_person[i] for i in top_indices],\n",
        "                yticklabels=[label_to_person[i] for i in top_indices])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(f'Confusion Matrix (Top {top_n} Classes)')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot confusion matrix for top 20 classes\n",
        "plot_confusion_matrix(true_labels, preds, top_n=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqxDwT8n074-"
      },
      "outputs": [],
      "source": [
        "# Function to make prediction on a single image\n",
        "def predict_image(model, image_path, transform):\n",
        "    # Load and preprocess the image\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Make prediction\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "\n",
        "    predicted_label = predicted.item()\n",
        "    predicted_person = label_to_person[predicted_label]\n",
        "\n",
        "    return predicted_person, output.squeeze(0)\n",
        "\n",
        "# Test on a random image\n",
        "def test_random_image():\n",
        "    # Select a random test image\n",
        "    random_idx = np.random.randint(len(test_df))\n",
        "    test_image_path = test_df.iloc[random_idx]['image_path']\n",
        "    true_label = test_df.iloc[random_idx]['label']\n",
        "    true_person = test_df.iloc[random_idx]['person']\n",
        "\n",
        "    # Make prediction\n",
        "    predicted_person, output = predict_image(model, test_image_path, test_transform)\n",
        "\n",
        "    # Display the image and prediction\n",
        "    image = Image.open(test_image_path)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(image)\n",
        "    plt.title(f'True: {true_person}\\nPredicted: {predicted_person}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Display top 5 predictions\n",
        "    probs = torch.softmax(output, dim=0)\n",
        "    top_probs, top_indices = torch.topk(probs, 5)\n",
        "\n",
        "    print(\"Top 5 predictions:\")\n",
        "    for i, (prob, idx) in enumerate(zip(top_probs.cpu().numpy(), top_indices.cpu().numpy())):\n",
        "        print(f\"{i+1}. {label_to_person[idx]}: {prob:.4f}\")\n",
        "\n",
        "# Test on a few random images\n",
        "for _ in range(3):\n",
        "    test_random_image()\n",
        "\n",
        "print(\"Training and evaluation complete! The model has been saved as 'best_vit_lfw_model.pth'\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18b84fd5836244dc99b945b4284e5f08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "227173aa7e5d4142aac9d8e2c17b130a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2906f89673614277a53a2fef61aa0beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1eca1d783ad467997a267a6b61dfec5",
            "placeholder": "",
            "style": "IPY_MODEL_8e760bc0d1a449fb934b99fce9116f23",
            "value": "Evaluating:100%"
          }
        },
        "33f2e68bfe2f4568b32a9f4d70d5e87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c912e3ba4e54cd59cb56d88144d31f8",
            "placeholder": "",
            "style": "IPY_MODEL_516fdaaeefff44cc811c2a2b099b4455",
            "value": "9/217[02:49&lt;1:03:58,18.45s/it]"
          }
        },
        "41e35a849538485bb16b414c86d15634": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "460e69820bcf48dda831030fec5044a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2906f89673614277a53a2fef61aa0beb",
              "IPY_MODEL_56567c26986b4bfa819d145770dab87c",
              "IPY_MODEL_fc1e32eb99174a20b185be1ceb081f31"
            ],
            "layout": "IPY_MODEL_7d14230e44b24a1b8a0297a5d2025ef1"
          }
        },
        "49bdd5d56c044345a9edbb4dc03fd083": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f87675c770d420781503b68fe783361": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18b84fd5836244dc99b945b4284e5f08",
            "placeholder": "",
            "style": "IPY_MODEL_b615e869ed104fc99c61f77e6b7a8784",
            "value": "Training:4%"
          }
        },
        "516fdaaeefff44cc811c2a2b099b4455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56567c26986b4bfa819d145770dab87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69027df48998421aafe79553abfadbaf",
            "max": 55,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_227173aa7e5d4142aac9d8e2c17b130a",
            "value": 55
          }
        },
        "69027df48998421aafe79553abfadbaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aa7da076b874e55b274814cb086bc58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b806e317922f4badbd806edca1980233",
            "max": 217,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41e35a849538485bb16b414c86d15634",
            "value": 9
          }
        },
        "6c912e3ba4e54cd59cb56d88144d31f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cd09a1b31c5453a89b24e243e439805": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49bdd5d56c044345a9edbb4dc03fd083",
            "max": 217,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a40c92eec50c4842a142234253e6d8d7",
            "value": 217
          }
        },
        "6facbbd81e3c4a61826f50d6542ef41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98c1a6aa84114cbdba324924121dff27",
            "placeholder": "",
            "style": "IPY_MODEL_b52630bbce9b4a92901b031b677ea291",
            "value": "217/217[1:05:24&lt;00:00,13.75s/it]"
          }
        },
        "703a241f542b430e949b3262f4b347dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e079f6d7f4949c8bd108ca7aba5c2b9",
              "IPY_MODEL_6cd09a1b31c5453a89b24e243e439805",
              "IPY_MODEL_6facbbd81e3c4a61826f50d6542ef41c"
            ],
            "layout": "IPY_MODEL_cbcafc897ffc4fa49e58ab7b61bcd99b"
          }
        },
        "7ca15af65f6b4a3983644c4b416c105f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f87675c770d420781503b68fe783361",
              "IPY_MODEL_6aa7da076b874e55b274814cb086bc58",
              "IPY_MODEL_33f2e68bfe2f4568b32a9f4d70d5e87c"
            ],
            "layout": "IPY_MODEL_97de03731d934faaa3f4b781983792eb"
          }
        },
        "7d14230e44b24a1b8a0297a5d2025ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e760bc0d1a449fb934b99fce9116f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97de03731d934faaa3f4b781983792eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98c1a6aa84114cbdba324924121dff27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e079f6d7f4949c8bd108ca7aba5c2b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8df3b6483ff48a8960e96dfa05a361c",
            "placeholder": "",
            "style": "IPY_MODEL_a99dde71ee344f15bdef9470826a2342",
            "value": "Training:100%"
          }
        },
        "a40c92eec50c4842a142234253e6d8d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8df3b6483ff48a8960e96dfa05a361c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a99dde71ee344f15bdef9470826a2342": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b52630bbce9b4a92901b031b677ea291": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b615e869ed104fc99c61f77e6b7a8784": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b806e317922f4badbd806edca1980233": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbcafc897ffc4fa49e58ab7b61bcd99b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccdbee6153434750b4df465b9d05570f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1eca1d783ad467997a267a6b61dfec5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df332bf7296f4f16aa8933c4b146af9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc1e32eb99174a20b185be1ceb081f31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccdbee6153434750b4df465b9d05570f",
            "placeholder": "",
            "style": "IPY_MODEL_df332bf7296f4f16aa8933c4b146af9c",
            "value": "55/55[04:58&lt;00:00,3.94s/it]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
